{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECAL Laser correction with Deep Learning\n",
    "\n",
    "Train a regression of the CMS ECAL transparency correction, using the information\n",
    "collected from the previous five readouts\n",
    "\n",
    "The input dataset consists of ROOT files with plain TTrees. Each file corresponds to a single crystal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the dataset\n",
    "! wget https://github.com/pierinim/tutorials/blob/master/RTA_Workshop/data.tar.gz?raw=true -O \"data.tar.gz\"\n",
    "! tar -xzf data.tar.gz\n",
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: pip: command not found\r\n"
     ]
    }
   ],
   "source": [
    "# we first install uproot to read the input data \n",
    "# and convert them to a numpy array\n",
    "! pip install uproot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot as ur\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iXrange = range(6,25)\n",
    "iYrange = range(131,140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transparency = np.array([])\n",
    "time = np.array([])\n",
    "time_in_fill = np.array([])\n",
    "lumi = np.array([])\n",
    "iX = np.array([])\n",
    "iY = np.array([])\n",
    "for i in iXrange:\n",
    "    for j in iYrange:\n",
    "        file = ur.open(\"data/BlueLaser_2017_rereco_v2_newformat.root.filter.%i.%i.0.public.root\" %(i,j))\n",
    "        ecalModule = file.get('laser')\n",
    "        my_transparency = ecalModule[\"transparency\"].array()\n",
    "        my_size = my_transparency.shape[0]\n",
    "        my_transparency = np.reshape(my_transparency, (my_size,1))\n",
    "        my_time = ecalModule[\"time\"].array()\n",
    "        my_time = np.reshape(my_time, (my_size,1))\n",
    "        my_time_in_fill = ecalModule[\"time_in_fill\"].array()\n",
    "        my_time_in_fill = np.reshape(my_time_in_fill, (my_size,1))\n",
    "        my_lumi = ecalModule[\"lumi\"].array()\n",
    "        my_lumi = np.reshape(my_lumi, (my_size,1))\n",
    "        my_iX = i*np.ones((my_size,1))\n",
    "        my_iY = j*np.ones((my_size,1))\n",
    "        transparency = np.concatenate((transparency, my_transparency), axis=-1) if transparency.size else my_transparency\n",
    "        time = np.concatenate((time, my_time), axis=-1) if time.size else my_time\n",
    "        time_in_fill = np.concatenate((time_in_fill, my_time_in_fill), axis=-1) if time_in_fill.size else my_time_in_fill\n",
    "        lumi = np.concatenate((lumi, my_lumi), axis=-1) if lumi.size else my_lumi\n",
    "        iX = np.concatenate((iX, my_iX), axis=-1) if iX.size else my_iX\n",
    "        iY = np.concatenate((iY, my_iY), axis=-1) if iY.size else my_iY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lumi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# luminosity\n",
    "plt.plot(time, lumi)\n",
    "plt.ylabel('Luminosity~$*~10^{-34}$')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transparency\n",
    "plt.plot(time, transparency)\n",
    "plt.ylabel('Transparency')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time in fill\n",
    "plt.plot(time_in_fill, transparency)\n",
    "plt.ylabel('Time in Fill')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple DNN application example\n",
    "\n",
    "We consider one crystal as the training dataset.\n",
    "The target is the transparency at thhe next readout, given\n",
    "- the transparency of the last 5 readouts\n",
    "- their time \n",
    "- their time in fill\n",
    "- the luminosity\n",
    "- the time of the next readout\n",
    "- the time in fill of the next readout\n",
    "- the lumi of the next readout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_transparency = transparency[:,0]\n",
    "my_time = time[:,0]\n",
    "my_time_in_fill = time_in_fill[:,0]\n",
    "my_lumi = lumi[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 readouts * (transparency, time, time in fill, luminosity) + 3 features for next readout = 23 features\n",
    "X = np.array([])\n",
    "Y = my_transparency[5:]\n",
    "TimeY = my_time[5:]\n",
    "for i in range(5,my_transparency.shape[0]):\n",
    "    mydata = np.array(my_transparency[i-5:i])\n",
    "    mydata = np.concatenate((mydata,my_time[i-5:i],my_time_in_fill[i-5:i],my_lumi[i-5:i]))\n",
    "    mydata = np.concatenate((mydata, np.array([my_time[i],my_time_in_fill[i],my_lumi[i]])))\n",
    "    mydata = np.reshape(mydata, (1,mydata.shape[0]))\n",
    "    X = np.concatenate((X, mydata)) if X.size else mydata\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reserve the last 504 readouts for testing\n",
    "X_test = X[2600:,:]\n",
    "Y_test= Y[2600:]\n",
    "TimeY_test= TimeY[2600:]\n",
    "X = X[:2600,:]\n",
    "Y = Y[:2600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now want to split the rest in training and validation in ~2:1 \n",
    "# first, we define a mask that is true at the 3rd, 6th, 9th, ... entry\n",
    "entries = np.array(range(X.shape[0]))\n",
    "one_every_three = (entries+1) % 3 == 0\n",
    "two_every_three = (entries+1) % 3 != 0\n",
    "print(one_every_three[:10])\n",
    "print(two_every_three[:10])\n",
    "\n",
    "# and then define the dataset\n",
    "X_val = X[one_every_three]\n",
    "Y_val = Y[one_every_three]\n",
    "TimeY_val = Y[one_every_three]\n",
    "X_train = X[two_every_three]\n",
    "Y_train = Y[two_every_three]\n",
    "TimeY_train = Y[two_every_three]\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "print(Y_train.shape, Y_val.shape, Y_test.shape)\n",
    "print(TimeY_train.shape, TimeY_val.shape, TimeY_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras imports\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, Concatenate, Reshape, BatchNormalization, Activation\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.utils import plot_model\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, TerminateOnNaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputLayer = Input(shape=(X_train.shape[1],))\n",
    "x = BatchNormalization()(inputLayer)\n",
    "#\n",
    "x = Dense(20, kernel_initializer='lecun_uniform', name='dense_relu1')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "#\n",
    "x = Dense(10, kernel_initializer='lecun_uniform', name='dense_relu2')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)#\n",
    "x = Dense(30, kernel_initializer='lecun_uniform', name='dense_relu3')(x)\n",
    "#\n",
    "x = Dense(5, kernel_initializer='lecun_uniform', name='dense_relu4')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "#\n",
    "outputLayer = Dense(1, activation='sigmoid', kernel_initializer='lecun_uniform', name = 'output')(x)\n",
    "model = Model(inputs=inputLayer, outputs=outputLayer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mape')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train \n",
    "history = model.fit(X_train, Y_train, epochs=500, batch_size=128, verbose = 2,\n",
    "                  validation_data=(X_val, Y_val),\n",
    "                 callbacks = [\n",
    "                EarlyStopping(monitor='val_loss', patience=10, verbose=1),\n",
    "                ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1),\n",
    "                TerminateOnNaN()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.semilogy()\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat = model.predict(X_test)\n",
    "Y_hat = np.reshape(Y_hat,(Y_hat.shape[0],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# true distribution\n",
    "plt.scatter(TimeY_test,Y_test, label = \"True\")\n",
    "plt.ylabel('Transparency')\n",
    "plt.xlabel('Time')\n",
    "plt.show()\n",
    "\n",
    "# true distribution\n",
    "plt.plot(TimeY_test,Y_test, label = \"True\")\n",
    "plt.plot(TimeY_test,Y_hat, label = \"Predicted\")\n",
    "plt.ylabel('Transparency')\n",
    "plt.xlabel('Time')\n",
    "plt.legend()\n",
    "plt.ylim((0.5,1))\n",
    "plt.show()\n",
    "\n",
    "# true distribution\n",
    "plt.scatter(TimeY_test,Y_test, label = \"True\", alpha=0.5)\n",
    "plt.scatter(TimeY_test,Y_hat, label = \"Predicted\", alpha=0.5)\n",
    "plt.ylabel('Transparency')\n",
    "plt.xlabel('Time')\n",
    "plt.legend()\n",
    "plt.ylim((0.5,1))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(TimeY_test,Y_test-Y_hat, label = \"Residual\")\n",
    "plt.ylabel('Transparency Residual')\n",
    "plt.xlabel('Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

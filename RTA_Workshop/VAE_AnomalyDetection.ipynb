{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Variational Autoencoder for jet images with  **Conv 2D**  \n",
    "\n",
    "---\n",
    "In this notebook, we train a Variational Autoencoder on a dataset of QCD jet images.\n",
    "Both the encoder and decoder networks are based on Conv2D architectures. \n",
    "This autoencoder can be used\n",
    "- as a clustering algorithm in the latent space\n",
    "- as a compression algorithm\n",
    "- as a generator \n",
    "- as an anomaly detection algorithm\n",
    "\n",
    "Some of these functionalities are exploited below.\n",
    "\n",
    "The notebook starts prpearing the QCD dataset and a set of\n",
    "\"anomalous jets\" (boosted W-, Z-, and top-jets).\n",
    "The VAE is trained on a training+validation dataset. Then, \n",
    "it is used on the test dataset for some of the applications listed above. Due to\n",
    "the low statistics available, the validation dataset is recycled\n",
    "as a test dataset. \n",
    "\n",
    "For details on the dataset, see https://github.com/pierinim/tutorials/blob/master/HiggsSchool/Lecture1/Notebook1_ExploreDataset.ipynb\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation of the training and validation samples\n",
    "\n",
    "---\n",
    "In order to import the dataset, we now\n",
    "- clone the dataset repository (to import the data in Colab)\n",
    "- load the h5 files in the data/ repository\n",
    "- extract the data we need: a target and jetImage \n",
    "\n",
    "To type shell commands, we start the command line with !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/pierinim/tutorials.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls tutorials/Data/JetDataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "target = np.array([])\n",
    "jetImage = np.array([])\n",
    "#----------\n",
    "# if you are running locally, you should do\n",
    "# datafiles = glob.glob(\"../Data/JetDataset/*h5\") \n",
    "#----------\n",
    "# on Colab\n",
    "#----------\n",
    "datafiles = glob.glob(\"tutorials/Data/JetDataset/*h5\") \n",
    "for fileIN in datafiles:\n",
    "    print(\"Appending %s\" %fileIN)\n",
    "    f = h5py.File(fileIN, \"r\")\n",
    "    myjetImage = np.array(f.get(\"jetImage\"), np.float32)\n",
    "    mytarget = np.array(f.get('jets')[0:,-6:-1], np.float32)\n",
    "    jetImage = np.concatenate([jetImage, myjetImage], axis=0) if jetImage.size else myjetImage\n",
    "    target = np.concatenate([target, mytarget], axis=0) if target.size else mytarget\n",
    "    f.close()\n",
    "print(target.shape, jetImage.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In keras, images are representable as $n \\times m \\times k$ tensors, where $n \\times m$ are the pixel dimenions and $k$ is the number of channels (e.g., 1 in a black\\&while image, 3 for an RGB image). In our case, k=1. To comply to this, we add the channel index by reshaping the image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jetImage = jetImage.reshape((jetImage.shape[0], jetImage.shape[1], jetImage.shape[2], 1))\n",
    "print(jetImage.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now separate the dataset in 4:\n",
    "- a training dataset, consisting of quarks and gluons\n",
    "- three 'anomalous jets' samples: W, Z, and top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jetImage_standard = jetImage[np.argmax(target,axis=1)<2]\n",
    "jetImage_W = jetImage[np.argmax(target,axis=1)==2]\n",
    "jetImage_Z = jetImage[np.argmax(target,axis=1)==3]\n",
    "jetImage_t = jetImage[np.argmax(target,axis=1)==4]\n",
    "print(jetImage_standard.shape, jetImage_W.shape, jetImage_Z.shape, jetImage_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this is an unsupervised algorithm, so we don't need the target array anymore.\n",
    "Nevertheless, we keep a part of it around, since it might be useful to test the response \n",
    "of the algorithm to quarks and gluons separetly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_standard = target[np.argmax(target,axis=1)<2]\n",
    "# some cleanup to save memory\n",
    "del target\n",
    "del jetImage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now shuffle the standard-jet data and its labels, splitting them into a training, a validation+test dataset with 2:1:1 ratio. \n",
    "\n",
    "Then we separate the validation+test in two halves (training and validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, label_train, label_val = t= train_test_split(jetImage_standard, label_standard, test_size=0.5)\n",
    "print(X_train.shape, X_val.shape, label_train.shape, label_val.shape)\n",
    "len_val = X_val.shape[0]\n",
    "X_test = X_val[int(len_val/2.):,:,:,:]\n",
    "label_test = label_val[int(len_val/2.):,:]\n",
    "X_val = X_val[:int(len_val/2.),:,:,:]\n",
    "label_test = label_val[:int(len_val/2.),:]\n",
    "print(X_train.shape, X_val.shape, X_test.shape, label_train.shape, label_val.shape, label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some more cleanup\n",
    "del jetImage_standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the ConVAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras imports\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Conv2D, Flatten, Activation, Deconv2D, Lambda\n",
    "from keras.layers import MaxPooling2D, BatchNormalization, Activation, Reshape, UpSampling2D\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.losses import mse\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, TerminateOnNaN\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = X_train.shape[1]\n",
    "img_cols = X_train.shape[2]\n",
    "image_shape = (img_rows, img_cols, 1)\n",
    "latent_dim = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------\n",
    "# Normal Sampling function for latent space\n",
    "#---------------------------\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean = 0 and std = 1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "#---------\n",
    "# Enncoder\n",
    "#---------\n",
    "inputImage = Input(shape=(image_shape))\n",
    "#\n",
    "x = Conv2D(10, kernel_size=(5, 5), data_format=\"channels_last\", strides=(1, 1), padding=\"same\")(inputImage)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D( pool_size = (5, 5))(x)\n",
    "#\n",
    "x = Conv2D(15, kernel_size=(4, 4), data_format=\"channels_last\", strides=(1, 1), padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D( pool_size = (5, 5))(x)\n",
    "#\n",
    "x = Conv2D(20, kernel_size=(4, 4), data_format=\"channels_last\", strides=(1, 1), padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = MaxPooling2D( pool_size = (4, 4))(x)\n",
    "#\n",
    "x = Flatten()(x)\n",
    "x = Dense(10, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim)(x)\n",
    "z_log_var = Dense(latent_dim)(x)\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "encoder = Model(inputImage, [z_mean, z_log_var, z], name='encoder')\n",
    "print(\"=== ENCODER ===\")\n",
    "encoder.summary()\n",
    "\n",
    "#---------\n",
    "# Decoder\n",
    "#---------\n",
    "latent_input = Input(shape=(latent_dim,))\n",
    "x = Dense(20, activation='relu')(latent_input)\n",
    "x = Reshape((1, 1, 20))(x)\n",
    "#\n",
    "x = UpSampling2D((4, 4))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Deconv2D(15, kernel_size=(4,4), data_format=\"channels_last\", strides=(1, 1), padding=\"same\")(x)\n",
    "x = Activation('relu')(x)\n",
    "#\n",
    "x = UpSampling2D((5, 5))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Deconv2D(10, kernel_size=(4,4), data_format=\"channels_last\", strides=(1, 1), padding=\"same\")(x)\n",
    "x = Activation('relu')(x)\n",
    "#\n",
    "x = UpSampling2D((5, 5))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Deconv2D(1, kernel_size=(4,4), data_format=\"channels_last\", strides=(1, 1), padding=\"same\")(x)\n",
    "dec = Activation('relu')(x)\n",
    "decoder = Model(latent_input, dec, name = 'decoder')\n",
    "print(\"=== DECODER ===\")\n",
    "decoder.summary()\n",
    "\n",
    "# instantiate VAE model\n",
    "outputs = decoder(encoder(inputImage)[2])\n",
    "vae = Model(inputImage, outputs, name='vae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y_true, y_pred):\n",
    "    return mse(tf.reshape(y_true, [-1,100*100]), tf.reshape(y_pred, [-1, 100*100]))\n",
    "\n",
    "def vae_loss(y_true, y_pred):\n",
    "    reconstruction_loss = mean_squared_error(y_true, y_pred)\n",
    "    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "    kl_loss = K.sum(kl_loss, axis=-1)\n",
    "    return K.mean(reconstruction_loss - 0.5 * kl_loss)\n",
    "\n",
    "vae.compile(optimizer='adam', loss=vae_loss)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train the model. Notice the difference with respect to the supervised case\n",
    "- the input to the training is (X,X) and nor (X, y). Similarly for the validation dataset\n",
    "- the model has no dropout. It is difficult for an unsupervised model to overtran, so there is not really a need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train \n",
    "history = vae.fit(X_train, X_train, epochs=n_epochs, batch_size=batch_size, verbose = 2,\n",
    "                validation_data=(X_val, X_val),\n",
    "                callbacks = [\n",
    "                EarlyStopping(monitor='val_loss', patience=10, verbose=1),\n",
    "                ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1),\n",
    "                TerminateOnNaN()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training history\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.yscale('log')\n",
    "plt.title('Training History')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: \n",
    "To save the model, you can do (not needed here):\n",
    "\n",
    "`model_json = autoencoder.to_json()\n",
    "with open(\"tutorials/HiggsSchool/models/jetAE_Conv2D.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "autoencoder.save_weights(\"tutorials/HiggsSchool/models/jetAE_Conv2D.h5\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection\n",
    "\n",
    "In order to detect anomalous jets, we build the distribution of the reconstruction loss (the MSE term) and define as anomaly all the jets falling in the tail, at some fixed p-value. \n",
    "To evaluate the strength of the test, we can consider a set of anomalies and evaluate the ROC curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['W', 'Z', 'top']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly = [jetImage_W, jetImage_Z, jetImage_t]\n",
    "predictedQCD = vae.predict(X_test)\n",
    "predicted_anomaly = []\n",
    "for i in range(len(labels)):\n",
    "    predicted_anomaly.append(vae.predict(anomaly[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(image_in, image_out):\n",
    "    mse = (image_out-image_in)*(image_out-image_in)\n",
    "    # sum over channel\n",
    "    mse = np.sum(mse,axis=-1)\n",
    "    # sum over y\n",
    "    mse = np.sum(mse, axis=-1)\n",
    "    # sum over x\n",
    "    mse = np.sum(mse, axis=-1)\n",
    "    return mse    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossQCD = mse(X_test, predictedQCD)\n",
    "loss_anomaly = []\n",
    "for i in range(len(labels)):\n",
    "    loss_anomaly.append(mse(anomaly[i], predicted_anomaly[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxScore = np.max(lossQCD)\n",
    "# plot QCD\n",
    "plt.figure()\n",
    "plt.hist(lossQCD, bins=100, label='QCD', density=True, range=(0, maxScore), \n",
    "         histtype='step', fill=False, linewidth=1.5)\n",
    "for i in range(len(labels)):\n",
    "    plt.hist(loss_anomaly[i], bins=100, label=labels[i], density=True, range=(0, maxScore),\n",
    "            histtype='step', fill=False, linewidth=1.5)\n",
    "plt.semilogy()\n",
    "plt.xlabel(\"VAE Loss\")\n",
    "plt.ylabel(\"Probability (a.u.)\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "plt.figure()\n",
    "targetQCD = np.zeros(lossQCD.shape[0])\n",
    "for i, label in enumerate(labels):\n",
    "        print(loss_anomaly[i].shape, targetQCD.shape)\n",
    "        trueVal = np.concatenate((np.ones(loss_anomaly[i].shape[0]),targetQCD))\n",
    "        predVal = np.concatenate((loss_anomaly[i],lossQCD))\n",
    "        print(trueVal.shape, predVal.shape)\n",
    "        fpr, tpr, threshold = roc_curve(trueVal,predVal)\n",
    "        auc1= auc(fpr, tpr)\n",
    "        plt.plot(tpr,fpr,label='%s Anomaly Detection, auc = %.1f%%'%(label,auc1*100.))\n",
    "plt.semilogy()\n",
    "plt.xlabel(\"sig. efficiency\")\n",
    "plt.ylabel(\"bkg. mistag rate\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator\n",
    "\n",
    "Sampling randome numbers from Gaus(0,1), we can generate a sample\n",
    "of points in the latent space, which we can pass to the decoder to\n",
    "generate jet images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sample of Gaussian numbers, with mean = 0 and sigma = 1\n",
    "z_gen = np.random.normal(0., 1., (X_val.shape[0],latent_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the decoder on these points of the latent space\n",
    "X_gen = decoder.predict(z_gen)\n",
    "print(X_gen.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Image\n",
    "from matplotlib.colors import LogNorm\n",
    "labelCat= [\"gluon\", \"quark\", \"W\", \"Z\", \"top\"]\n",
    "images = [X_val[:,:,:,0], X_gen[:,:,:,0]]\n",
    "labelAveImage = [\"Input\",\"VAE\"]\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "for i in range(len(images)):\n",
    "    SUM_Image = np.sum(images[i], axis = 0)\n",
    "    plt.imshow(SUM_Image/float(images[i].shape[0]), origin='lower',norm=LogNorm(vmin=0.01))\n",
    "    plt.colorbar()\n",
    "    plt.title(labelAveImage[i], fontsize=15)\n",
    "    plt.xlabel(\"$\\Delta\\eta$ cell\", fontsize=15)\n",
    "    plt.ylabel(\"$\\Delta\\phi$ cell\", fontsize=15)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import moment\n",
    "# compute some quantity that we want to plot\n",
    "def moments(myImages, projAxis):\n",
    "    xProj = np.sum(myImages, axis=projAxis)\n",
    "    moments = moment(xProj, moment = 1)\n",
    "    rms = np.sqrt(moment(xProj, moment = 2))\n",
    "    moments = np.concatenate((moments, rms), axis = 1)\n",
    "    moments = np.concatenate((moments, moment(xProj, moment = 3)), axis = 1)\n",
    "    moments = np.concatenate((moments, moment(xProj, moment = 4)), axis = 1)\n",
    "    return moments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot X and Y moments of the generated vs original distributions\n",
    "p_label = [\"E[$\\eta$]\", \"E[$\\eta^2$]\", \"E[$\\eta^3$]\", \"E[$\\eta^4$]\",\n",
    "          \"E[$\\phi$]\", \"E[$\\phi^2$]\", \"E[$\\phi^3$]\", \"E[$\\phi^4$]\",]\n",
    "p_gen = moments(X_gen, 1)\n",
    "p_gen = np.concatenate((p_gen, moments(X_gen, 2)), axis = 1)\n",
    "p_val = moments(X_val, 1)\n",
    "p_val = np.concatenate((p_val, moments(X_val, 2)), axis = 1)\n",
    "\n",
    "for i in range(p_gen.shape[1]):\n",
    "    f = plt.figure(i)\n",
    "    xmin = np.min(p_val[:,i])\n",
    "    xmax = np.max(p_val[:,i])    \n",
    "    plt.hist(p_val[:,i], bins=30, range=(xmin,xmax), histtype='step', fill=False, linewidth=1.5, density=True, label=\"Input\")\n",
    "    plt.hist(p_gen[:,i], bins=30, range=(xmin,xmax), histtype='step', fill=False, linewidth=1.5, density=True, label=\"VAE\")\n",
    "    plt.xlabel(p_label[i])\n",
    "    plt.yscale('log')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

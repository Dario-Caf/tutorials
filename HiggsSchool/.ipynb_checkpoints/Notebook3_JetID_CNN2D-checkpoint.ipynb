{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notebook3_JetID_CNN2D-checkpoint.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pierinim/tutorials/blob/master/HiggsSchool/.ipynb_checkpoints/Notebook3_JetID_CNN2D-checkpoint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5GYG3NKROZj",
        "colab_type": "text"
      },
      "source": [
        "# Jet Tagging with **Conv2D**\n",
        "\n",
        "---\n",
        "In this notebook, we perform a Jet identification task using a Conv2D multiclass classifier.\n",
        "The problem consists on identifying a given jet as a quark, a gluon, a W, a Z, or a top,\n",
        "based on a jet image, i.e., a 2D histogram of the transverse momentum ($p_T$) deposited in each of 100x100\n",
        "bins of a square window of the ($\\eta$, $\\phi$) plane, centered along the jet axis.\n",
        "\n",
        "For details on the physics problem, see https://arxiv.org/pdf/1804.06913.pdf \n",
        "\n",
        "For details on the dataset, see Notebook1\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj0BzrHhROZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import h5py\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saqdDWj4ROZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbNh3o-oROZs",
        "colab_type": "text"
      },
      "source": [
        "# Preparation of the training and validation samples\n",
        "\n",
        "---\n",
        "In order to import the dataset, we now\n",
        "- clone the dataset repository (to import the data in Colab)\n",
        "- load the h5 files in the data/ repository\n",
        "- extract the data we need: a target and jetImage \n",
        "\n",
        "To type shell commands in Colab, we start the command line with !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a3TjhviRlrw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9357ac48-c11d-4db6-92a5-16905110b18d"
      },
      "source": [
        "! git clone https://github.com/pierinim/tutorials.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'tutorials' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OS-5nSFgR0bN",
        "colab_type": "text"
      },
      "source": [
        "Now that the gitub repository is cloned, we can navigate through it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6vkwK7vRyb4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f898e2c0-29f3-497e-aefe-ffe0fd321700"
      },
      "source": [
        "! ls tutorials/HiggsSchool/data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "jetImage_7_100p_0_10000.h5\tjetImage_7_100p_50000_60000.h5\n",
            "jetImage_7_100p_10000_20000.h5\tjetImage_7_100p_60000_70000.h5\n",
            "jetImage_7_100p_30000_40000.h5\tjetImage_7_100p_70000_80000.h5\n",
            "jetImage_7_100p_40000_50000.h5\tjetImage_7_100p_80000_90000.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_BudR5zROZt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "4bdbf0cc-c908-4db6-8c31-aebe9a3e9818"
      },
      "source": [
        "target = np.array([])\n",
        "jetImage = np.array([])\n",
        "# we cannot load all data on Colab. So we just take a few files\n",
        "datafiles = ['tutorials/HiggsSchool/data/jetImage_7_100p_30000_40000.h5',\n",
        "           'tutorials/HiggsSchool/data/jetImage_7_100p_60000_70000.h5',\n",
        "            'tutorials/HiggsSchool/data/jetImage_7_100p_50000_60000.h5',\n",
        "            'tutorials/HiggsSchool/data/jetImage_7_100p_10000_20000.h5',\n",
        "            'tutorials/HiggsSchool/data/jetImage_7_100p_0_10000.h5']\n",
        "for fileIN in datafiles:\n",
        "    print(\"Appending %s\" %fileIN)\n",
        "    f = h5py.File(fileIN)\n",
        "    myjetImage = np.array(f.get(\"jetImage\"))\n",
        "    mytarget = np.array(f.get('jets')[0:,-6:-1])\n",
        "    jetImage = np.concatenate([jetImage, myjetImage], axis=0) if jetImage.size else myjetImage\n",
        "    target = np.concatenate([target, mytarget], axis=0) if target.size else mytarget\n",
        "    del mytarget, myjetImage\n",
        "print(target.shape, jetImage.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Appending tutorials/HiggsSchool/data/jetImage_7_100p_30000_40000.h5\n",
            "Appending tutorials/HiggsSchool/data/jetImage_7_100p_60000_70000.h5\n",
            "Appending tutorials/HiggsSchool/data/jetImage_7_100p_50000_60000.h5\n",
            "Appending tutorials/HiggsSchool/data/jetImage_7_100p_10000_20000.h5\n",
            "Appending tutorials/HiggsSchool/data/jetImage_7_100p_0_10000.h5\n",
            "(50000, 5) (50000, 100, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFIRmSwWROZw",
        "colab_type": "text"
      },
      "source": [
        "The dataset consists of 50K jets, with up to 100 particles in each jet. These 100 particles have been used to fill the 100x100 jet images.\n",
        "\n",
        "---\n",
        "\n",
        "We now shuffle the data, splitting them into a training and a validation dataset with 2:1 ratio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOMfWSxeROZw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef880a1b-641a-4e37-d454-479b4fc7d28b"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(jetImage, target, test_size=0.33)\n",
        "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\n",
        "del jetImage, target"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(33500, 100, 100) (16500, 100, 100) (33500, 5) (16500, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "la3Z5AarROZz",
        "colab_type": "text"
      },
      "source": [
        "In keras, images are representable as $n \\times m \\times k$ tensors, where $n \\times m$ are the pixel dimenions and $k$ is the number of channels (e.g., 1 in a black\\&while image, 3 for an RGB image). In our case, k=1. To comply to this, we add the channel index by reshaping the image dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MX2Jw3MmROZz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93f4f6b8-ead8-48a9-ab6b-c06193c18f18"
      },
      "source": [
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
        "X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], X_val.shape[2], 1))\n",
        "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(33500, 100, 100, 1) (16500, 100, 100, 1) (33500, 5) (16500, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcwOfrBzROZ2",
        "colab_type": "text"
      },
      "source": [
        "# Conv 2D model building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAC6zHnFROZ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb62bb01-df61-4010-8618-16801aec5aa8"
      },
      "source": [
        "# keras imports\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input, Conv2D, Dropout, Flatten\n",
        "from keras.layers import MaxPooling2D, BatchNormalization, Activation\n",
        "from keras.utils import plot_model\n",
        "from keras import backend as K\n",
        "from keras import metrics\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, TerminateOnNaN"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hAdQwrWROZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_rows = X_train.shape[1]\n",
        "img_cols = X_train.shape[2]\n",
        "dropoutRate = 0.25"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhwzL_tqROZ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "30dfc19a-7fa6-426b-8a69-03099f332dd4"
      },
      "source": [
        "image_shape = (img_rows, img_cols, 1)\n",
        "####\n",
        "inputImage = Input(shape=(image_shape))\n",
        "x = Conv2D(5, kernel_size=(5,5), data_format=\"channels_last\", strides=(1, 1), padding=\"same\")(inputImage)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling2D( pool_size = (5,5))(x)\n",
        "x = Dropout(dropoutRate)(x)\n",
        "#\n",
        "x = Conv2D(3, kernel_size=(3,3), data_format=\"channels_last\", strides=(1, 1), padding=\"same\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling2D( pool_size = (3,3))(x)\n",
        "x = Dropout(dropoutRate)(x)\n",
        "#\n",
        "x = Flatten()(x)\n",
        "#\n",
        "x = Dense(5, activation='relu')(x)\n",
        "#\n",
        "output = Dense(5, activation='softmax')(x)\n",
        "####\n",
        "model = Model(inputs=inputImage, outputs=output)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtrdkginROZ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "d84a6d6b-0107-4ebb-ed67-afc506acaf0b"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 100, 100, 1)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 100, 100, 5)       130       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 100, 100, 5)       20        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 100, 100, 5)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 20, 20, 5)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 20, 20, 5)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 20, 20, 3)         138       \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 20, 20, 3)         12        \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 20, 20, 3)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 3)           0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 6, 6, 3)           0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 108)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 545       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 30        \n",
            "=================================================================\n",
            "Total params: 875\n",
            "Trainable params: 859\n",
            "Non-trainable params: 16\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF0778zIROaA",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "We now train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgyiQ1tSROaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "n_epochs = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiU7to01ROaD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "78de450c-ffd7-4fff-94cd-c4ad94f0bfb0"
      },
      "source": [
        "# train \n",
        "history = model.fit(X_train, y_train, epochs=n_epochs, batch_size=batch_size, verbose = 2,\n",
        "                validation_data=(X_val, y_val),\n",
        "                callbacks = [\n",
        "                EarlyStopping(monitor='val_loss', patience=10, verbose=1),\n",
        "                ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1),\n",
        "                TerminateOnNaN()])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 33500 samples, validate on 16500 samples\n",
            "Epoch 1/100\n",
            " - 9s - loss: 1.2495 - val_loss: 1.1813\n",
            "Epoch 2/100\n",
            " - 9s - loss: 1.2366 - val_loss: 1.1703\n",
            "Epoch 3/100\n",
            " - 10s - loss: 1.2277 - val_loss: 1.1667\n",
            "Epoch 4/100\n",
            " - 9s - loss: 1.2198 - val_loss: 1.1484\n",
            "Epoch 5/100\n",
            " - 9s - loss: 1.2114 - val_loss: 1.1389\n",
            "Epoch 6/100\n",
            " - 9s - loss: 1.2078 - val_loss: 1.1345\n",
            "Epoch 7/100\n",
            " - 9s - loss: 1.1959 - val_loss: 1.1211\n",
            "Epoch 8/100\n",
            " - 9s - loss: 1.1902 - val_loss: 1.1233\n",
            "Epoch 9/100\n",
            " - 9s - loss: 1.1880 - val_loss: 1.1146\n",
            "Epoch 10/100\n",
            " - 9s - loss: 1.1807 - val_loss: 1.1108\n",
            "Epoch 11/100\n",
            " - 9s - loss: 1.1737 - val_loss: 1.1096\n",
            "Epoch 12/100\n",
            " - 9s - loss: 1.1700 - val_loss: 1.0994\n",
            "Epoch 13/100\n",
            " - 9s - loss: 1.1578 - val_loss: 1.0987\n",
            "Epoch 14/100\n",
            " - 9s - loss: 1.1611 - val_loss: 1.0985\n",
            "Epoch 15/100\n",
            " - 9s - loss: 1.1548 - val_loss: 1.0889\n",
            "Epoch 16/100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LGESQNsROaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot training history\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.yscale('log')\n",
        "plt.title('Training History')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training', 'validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S15Mua6PROaI",
        "colab_type": "text"
      },
      "source": [
        "We save on disk the best model, result of the training, to be then use for inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USl_xxjOROaI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ModelName = 'Conv2D'\n",
        "model_json = model.to_json()\n",
        "with open(\"models/jetTagger_Conv2D.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights(\"models/jetTagger_Conv2D.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEv5JjGNROaK",
        "colab_type": "text"
      },
      "source": [
        "# Building the ROC Curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2xqGRrnROaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = ['gluon', 'quark', 'W', 'Z', 'top']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3BsrLpIROaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "predict_val = model.predict(X_val)\n",
        "df = pd.DataFrame()\n",
        "fpr = {}\n",
        "tpr = {}\n",
        "auc1 = {}\n",
        "\n",
        "plt.figure()\n",
        "for i, label in enumerate(labels):\n",
        "        df[label] = y_val[:,i]\n",
        "        df[label + '_pred'] = predict_val[:,i]\n",
        "\n",
        "        fpr[label], tpr[label], threshold = roc_curve(df[label],df[label+'_pred'])\n",
        "\n",
        "        auc1[label] = auc(fpr[label], tpr[label])\n",
        "\n",
        "        plt.plot(tpr[label],fpr[label],label='%s tagger, auc = %.1f%%'%(label,auc1[label]*100.))\n",
        "plt.semilogy()\n",
        "plt.xlabel(\"sig. efficiency\")\n",
        "plt.ylabel(\"bkg. mistag rate\")\n",
        "plt.ylim(0.000001,1)\n",
        "plt.grid(True)\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9vn-fKhROaQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an Anomalous Jet Detector with **RNN** \n",
    "\n",
    "---\n",
    "In this notebook, we train an unsupervised algorithm capable of compressing a jet image into a low-dimension laten space and, from there, reconstruct the input image. The distance between the input and te output is used to identify rare jet configurations. Applying a lower treshold on the loss, one can veto standard QCD jets (quarks and gluons) and select a sample enriched in anomalous jets (W, Z, top, etc). The model uses (De)Conv2D and Dense layers to process the image.\n",
    "\n",
    "This is based on the following papers:\n",
    "- https://arxiv.org/pdf/1808.08992.pdf\n",
    "- https://arxiv.org/pdf/1808.08979.pdf\n",
    "\n",
    "For details on the dataset, see Notebook1 and Notebook3\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation of the training and validation samples\n",
    "\n",
    "---\n",
    "In order to import the dataset, we now\n",
    "- clone the dataset repository (to import the data in Colab)\n",
    "- load the h5 files in the data/ repository\n",
    "- extract the data we need: a target and jetImage \n",
    "\n",
    "To type shell commands, we start the command line with !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'tutorials' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/pierinim/tutorials.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jetImage_7_100p_0_10000.h5     jetImage_7_100p_50000_60000.h5\r\n",
      "jetImage_7_100p_10000_20000.h5 jetImage_7_100p_60000_70000.h5\r\n",
      "jetImage_7_100p_30000_40000.h5 jetImage_7_100p_70000_80000.h5\r\n",
      "jetImage_7_100p_40000_50000.h5 jetImage_7_100p_80000_90000.h5\r\n"
     ]
    }
   ],
   "source": [
    "! ls tutorials/HiggsSchool/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending tutorials/HiggsSchool/data/jetImage_7_100p_30000_40000.h5\n",
      "Appending tutorials/HiggsSchool/data/jetImage_7_100p_60000_70000.h5\n",
      "Appending tutorials/HiggsSchool/data/jetImage_7_100p_50000_60000.h5\n",
      "Appending tutorials/HiggsSchool/data/jetImage_7_100p_10000_20000.h5\n",
      "Appending tutorials/HiggsSchool/data/jetImage_7_100p_0_10000.h5\n",
      "(50000, 5) (50000, 100, 16)\n"
     ]
    }
   ],
   "source": [
    "target = np.array([])\n",
    "jetList = np.array([])\n",
    "# we cannot load all data on Colab. So we just take a few files\n",
    "datafiles = ['tutorials/HiggsSchool/data/jetImage_7_100p_30000_40000.h5',\n",
    "           'tutorials/HiggsSchool/data/jetImage_7_100p_60000_70000.h5',\n",
    "            'tutorials/HiggsSchool/data/jetImage_7_100p_50000_60000.h5',\n",
    "            'tutorials/HiggsSchool/data/jetImage_7_100p_10000_20000.h5',\n",
    "            'tutorials/HiggsSchool/data/jetImage_7_100p_0_10000.h5']\n",
    "# if you are running locallt, you can use the full dataset doing\n",
    "# for fileIN in glob.glob(\"tutorials/HiggsSchool/data/*h5\"):\n",
    "for fileIN in datafiles:\n",
    "    print(\"Appending %s\" %fileIN)\n",
    "    f = h5py.File(fileIN)\n",
    "    myJetList = np.array(f.get(\"jetConstituentList\"))\n",
    "    mytarget = np.array(f.get('jets')[0:,-6:-1])\n",
    "    jetList = np.concatenate([jetList, myJetList], axis=0) if jetList.size else myJetList\n",
    "    target = np.concatenate([target, mytarget], axis=0) if target.size else mytarget\n",
    "print(target.shape, jetList.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now separate the dataset in 4:\n",
    "- a training dataset, consisting of quarks and gluons\n",
    "- three 'anomalous jets' samples: W, Z, and top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19908, 100, 16) (10015, 100, 16) (10037, 100, 16) (10040, 100, 16)\n"
     ]
    }
   ],
   "source": [
    "jetList_standard = jetList[np.argmax(target,axis=1)<2]\n",
    "jetList_W = jetList[np.argmax(target,axis=1)==2]\n",
    "jetList_Z = jetList[np.argmax(target,axis=1)==3]\n",
    "jetList_t = jetList[np.argmax(target,axis=1)==4]\n",
    "print(jetList_standard.shape, jetList_W.shape, jetList_Z.shape, jetList_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this is an unsupervised algorithm, so we don't need the target array anymore.\n",
    "Nevertheless, we keep a part of it around, since it might be useful to test the response \n",
    "of the algorithm to quarks and gluons separetly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_standard = target[np.argmax(target,axis=1)<2]\n",
    "del target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now shuffle the standard-jet data and its labels, splitting them into a training, a validation+test dataset with 2:1:1 ratio. \n",
    "\n",
    "Then we separate the validation+test in two halves (training and validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9954, 100, 16) (9954, 100, 16) (9954, 5) (9954, 5)\n",
      "(9954, 100, 16) (4977, 100, 16) (4977, 100, 16) (9954, 5) (9954, 5) (4977, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, label_train, label_val = t= train_test_split(jetList_standard, label_standard, test_size=0.5)\n",
    "print(X_train.shape, X_val.shape, label_train.shape, label_val.shape)\n",
    "len_val = X_val.shape[0]\n",
    "X_test = X_val[int(len_val/2.):,:,:]\n",
    "label_test = label_val[int(len_val/2.):,:]\n",
    "X_val = X_val[:int(len_val/2.),:,:]\n",
    "label_test = label_val[:int(len_val/2.),:]\n",
    "print(X_train.shape, X_val.shape, X_test.shape, label_train.shape, label_val.shape, label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some cleanup to save memory\n",
    "del jetList, jetList_standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the ConvAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras imports\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, GRU, Activation\n",
    "from keras.layers import RepeatVector, Reshape\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, TerminateOnNaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 16)\n"
     ]
    }
   ],
   "source": [
    "featureArrayLength = (X_train.shape[1],X_train.shape[2])\n",
    "dropoutRate = 0.25\n",
    "print(featureArrayLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------\n",
    "# Enncoder\n",
    "#---------\n",
    "inputList = Input(shape=(featureArrayLength))\n",
    "x = GRU(20, activation=\"tanh\", recurrent_activation='hard_sigmoid', return_sequences=False)(inputList)\n",
    "x = Dense(5, activation='relu')(x)\n",
    "x = Dense(20, activation='relu')(x)\n",
    "x = RepeatVector(featureArrayLength[0])(x)\n",
    "outputList = GRU(16, activation=\"tanh\", recurrent_activation='hard_sigmoid', return_sequences=True, return_state=False)(x)\n",
    "####\n",
    "#\n",
    "autoencoder = Model(inputs=inputList, outputs=outputList)\n",
    "#\n",
    "#autoencoder = Model(inputs=inputList, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 100, 16)           0         \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 20)                2220      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 105       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                120       \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 100, 20)           0         \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 100, 16)           1776      \n",
      "=================================================================\n",
      "Total params: 4,221\n",
      "Trainable params: 4,221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.compile(loss='mse', optimizer='adam')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train the model. Notice the difference with respect to the supervised case\n",
    "- the input to the training is (X,X) and nor (X, y). Similarly for the validation dataset\n",
    "- the model has no dropout. It is difficult for an unsupervised model to overtran, so there is not really a need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9954 samples, validate on 4977 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 461.5776 - val_loss: 464.9009\n",
      "Epoch 2/100\n",
      " - 9s - loss: 460.4969 - val_loss: 464.2467\n",
      "Epoch 3/100\n",
      " - 10s - loss: 460.0882 - val_loss: 464.0253\n",
      "Epoch 4/100\n",
      " - 10s - loss: 459.9628 - val_loss: 463.9561\n",
      "Epoch 5/100\n",
      " - 10s - loss: 459.9130 - val_loss: 463.9137\n",
      "Epoch 6/100\n",
      " - 10s - loss: 459.8715 - val_loss: 463.8793\n",
      "Epoch 7/100\n",
      " - 10s - loss: 459.8435 - val_loss: 463.8536\n",
      "Epoch 8/100\n",
      " - 10s - loss: 459.8241 - val_loss: 463.8455\n",
      "Epoch 9/100\n",
      " - 9s - loss: 459.8203 - val_loss: 463.8436\n",
      "Epoch 10/100\n",
      " - 10s - loss: 459.8190 - val_loss: 463.8430\n",
      "Epoch 11/100\n",
      " - 11s - loss: 459.8181 - val_loss: 463.8420\n",
      "Epoch 12/100\n",
      " - 10s - loss: 459.8182 - val_loss: 463.8421\n",
      "Epoch 13/100\n",
      " - 10s - loss: 459.8170 - val_loss: 463.8407\n",
      "Epoch 14/100\n",
      " - 10s - loss: 459.8160 - val_loss: 463.8399\n",
      "Epoch 15/100\n",
      " - 10s - loss: 459.8155 - val_loss: 463.8398\n",
      "Epoch 16/100\n",
      " - 10s - loss: 459.8158 - val_loss: 463.8398\n",
      "Epoch 17/100\n",
      " - 9s - loss: 459.8152 - val_loss: 463.8394\n",
      "Epoch 18/100\n",
      " - 9s - loss: 459.8149 - val_loss: 463.8391\n",
      "Epoch 19/100\n",
      " - 9s - loss: 459.8144 - val_loss: 463.8387\n",
      "Epoch 20/100\n",
      " - 9s - loss: 459.8141 - val_loss: 463.8380\n",
      "Epoch 21/100\n",
      " - 10s - loss: 459.8138 - val_loss: 463.8379\n",
      "Epoch 22/100\n",
      " - 9s - loss: 459.8137 - val_loss: 463.8379\n",
      "Epoch 23/100\n",
      " - 9s - loss: 459.8135 - val_loss: 463.8375\n",
      "Epoch 24/100\n",
      " - 10s - loss: 459.8131 - val_loss: 463.8379\n",
      "Epoch 25/100\n",
      " - 9s - loss: 459.8131 - val_loss: 463.8374\n",
      "Epoch 26/100\n",
      " - 9s - loss: 459.8128 - val_loss: 463.8367\n",
      "Epoch 27/100\n",
      " - 9s - loss: 459.8124 - val_loss: 463.8365\n",
      "Epoch 28/100\n",
      " - 9s - loss: 459.8123 - val_loss: 463.8362\n",
      "Epoch 29/100\n",
      " - 9s - loss: 459.8119 - val_loss: 463.8362\n",
      "Epoch 30/100\n",
      " - 9s - loss: 459.8118 - val_loss: 463.8362\n",
      "Epoch 31/100\n",
      " - 9s - loss: 459.8117 - val_loss: 463.8361\n",
      "Epoch 32/100\n",
      " - 10s - loss: 459.8113 - val_loss: 463.8352\n",
      "Epoch 33/100\n",
      " - 9s - loss: 459.8119 - val_loss: 463.8377\n",
      "Epoch 34/100\n",
      " - 9s - loss: 459.8113 - val_loss: 463.8347\n",
      "Epoch 35/100\n",
      " - 9s - loss: 459.8101 - val_loss: 463.8350\n",
      "Epoch 36/100\n",
      " - 9s - loss: 459.8114 - val_loss: 463.8354\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      " - 10s - loss: 459.8100 - val_loss: 463.8349\n",
      "Epoch 38/100\n",
      " - 9s - loss: 459.8092 - val_loss: 463.8331\n",
      "Epoch 39/100\n",
      " - 9s - loss: 459.8087 - val_loss: 463.8329\n",
      "Epoch 40/100\n",
      " - 9s - loss: 459.8086 - val_loss: 463.8328\n",
      "Epoch 41/100\n",
      " - 9s - loss: 459.8085 - val_loss: 463.8328\n",
      "Epoch 42/100\n",
      " - 9s - loss: 459.8085 - val_loss: 463.8327\n",
      "Epoch 43/100\n",
      " - 9s - loss: 459.8084 - val_loss: 463.8326\n",
      "Epoch 44/100\n",
      " - 9s - loss: 459.8084 - val_loss: 463.8326\n",
      "Epoch 45/100\n",
      " - 9s - loss: 459.8083 - val_loss: 463.8326\n",
      "Epoch 46/100\n",
      " - 9s - loss: 459.8082 - val_loss: 463.8325\n",
      "Epoch 47/100\n",
      " - 9s - loss: 459.8081 - val_loss: 463.8325\n",
      "Epoch 48/100\n",
      " - 9s - loss: 459.8081 - val_loss: 463.8323\n",
      "Epoch 49/100\n",
      " - 9s - loss: 459.8080 - val_loss: 463.8323\n",
      "Epoch 50/100\n",
      " - 9s - loss: 459.8079 - val_loss: 463.8323\n",
      "Epoch 51/100\n",
      " - 9s - loss: 459.8079 - val_loss: 463.8321\n",
      "Epoch 52/100\n",
      " - 9s - loss: 459.8078 - val_loss: 463.8321\n",
      "Epoch 53/100\n",
      " - 9s - loss: 459.8078 - val_loss: 463.8320\n",
      "Epoch 54/100\n",
      " - 9s - loss: 459.8078 - val_loss: 463.8320\n",
      "Epoch 55/100\n",
      " - 10s - loss: 459.8077 - val_loss: 463.8321\n",
      "Epoch 56/100\n",
      " - 9s - loss: 459.8080 - val_loss: 463.8321\n",
      "Epoch 57/100\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      " - 9s - loss: 459.8077 - val_loss: 463.8320\n",
      "Epoch 58/100\n",
      " - 9s - loss: 459.8076 - val_loss: 463.8319\n",
      "Epoch 59/100\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      " - 9s - loss: 459.8075 - val_loss: 463.8319\n",
      "Epoch 60/100\n",
      " - 9s - loss: 459.8075 - val_loss: 463.8319\n",
      "Epoch 61/100\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      " - 9s - loss: 459.8075 - val_loss: 463.8319\n",
      "Epoch 62/100\n",
      " - 9s - loss: 459.8075 - val_loss: 463.8319\n",
      "Epoch 63/100\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      " - 9s - loss: 459.8075 - val_loss: 463.8319\n",
      "Epoch 64/100\n",
      " - 9s - loss: 459.8075 - val_loss: 463.8319\n",
      "Epoch 65/100\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      " - 9s - loss: 459.8075 - val_loss: 463.8319\n",
      "Epoch 66/100\n",
      " - 9s - loss: 459.8075 - val_loss: 463.8319\n",
      "Epoch 67/100\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      " - 10s - loss: 459.8075 - val_loss: 463.8319\n",
      "Epoch 68/100\n",
      " - 9s - loss: 459.8075 - val_loss: 463.8319\n",
      "Epoch 69/100\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      " - 9s - loss: 459.8075 - val_loss: 463.8319\n",
      "Epoch 70/100\n",
      " - 9s - loss: 459.8075 - val_loss: 463.8319\n",
      "Epoch 71/100\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      " - 9s - loss: 459.8075 - val_loss: 463.8319\n",
      "Epoch 00071: early stopping\n"
     ]
    }
   ],
   "source": [
    "# train \n",
    "history = autoencoder.fit(X_train, X_train, epochs=n_epochs, batch_size=batch_size, verbose = 2,\n",
    "                validation_data=(X_val, X_val),\n",
    "                callbacks = [\n",
    "                EarlyStopping(monitor='val_loss', patience=10, verbose=1),\n",
    "                ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1),\n",
    "                TerminateOnNaN()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x134e92470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training history\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "#plt.yscale('log')\n",
    "plt.title('Training History')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save on disk the best model, result of the training, to be then use for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tutorials/HiggsSchool/models/jetAE_RNN.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-446caca732f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tutorials/HiggsSchool/models/jetAE_RNN.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tutorials/HiggsSchool/models/jetAE_RNN.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tutorials/HiggsSchool/models/jetAE_RNN.json'"
     ]
    }
   ],
   "source": [
    "model_json = autoencoder.to_json()\n",
    "with open(\"tutorials/HiggsSchool/models/jetAE_RNN.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "autoencoder.save_weights(\"tutorials/HiggsSchool/models/jetAE_RNN.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['W', 'Z', 'top']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly = [jetList_W, jetList_Z, jetList_t]\n",
    "predictedQCD = autoencoder.predict(X_test)\n",
    "predicted_anomaly = []\n",
    "for i in range(len(labels)):\n",
    "    predicted_anomaly.append(autoencoder.predict(anomaly[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(List_in, List_out):\n",
    "    mse = (List_out-List_in)*(List_out-List_in)\n",
    "    # sum over channel\n",
    "    mse = np.sum(mse,axis=-1)\n",
    "    # sum over y\n",
    "    mse = np.sum(mse, axis=-1)\n",
    "    # sum over x\n",
    "    mse = np.sum(mse, axis=-1)\n",
    "    return mse    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossQCD = mse(X_test, predictedQCD)\n",
    "loss_anomaly = []\n",
    "for i in range(len(labels)):\n",
    "    loss_anomaly.append(mse(anomaly[i], predicted_anomaly[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "print(lossQCD.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x134796b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#maxScore = np.max(lossQCD)\n",
    "# plot QCD\n",
    "plt.figure()\n",
    "#plt.hist(lossQCD, bins=100, label='QCD', density=True, range=(0, maxScore), \n",
    "plt.hist(lossQCD, bins=100, label='QCD', density=True, \n",
    "         histtype='step', fill=False, linewidth=1.5)\n",
    "#for i in range(len(labels)):\n",
    "#    plt.hist(loss_anomaly[i], bins=100, label=labels[i], density=True, range=(0, maxScore),\n",
    "#            histtype='step', fill=False, linewidth=1.5)\n",
    "plt.semilogy()\n",
    "plt.xlabel(\"AE Loss\")\n",
    "plt.ylabel(\"Probability (a.u.)\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-d9baddfdf893>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtargetQCD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlossQCD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_anomaly\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetQCD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1932ab710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "plt.figure()\n",
    "targetQCD = np.zeros(lossQCD.shape[0])\n",
    "for i, label in enumerate(labels):\n",
    "        print(loss_anomaly[i].shape, targetQCD.shape)\n",
    "        trueVal = np.concatenate((np.ones(loss_anomaly[i].shape[0]),targetQCD))\n",
    "        predVal = np.concatenate((loss_anomaly[i],lossQCD))\n",
    "        print(trueVal.shape, predVal.shape)\n",
    "        fpr, tpr, threshold = roc_curve(trueVal,predVal)\n",
    "        auc1= auc(fpr, tpr)\n",
    "        plt.plot(tpr,fpr,label='%s Anomaly Detection, auc = %.1f%%'%(label,auc1*100.))\n",
    "plt.semilogy()\n",
    "plt.xlabel(\"sig. efficiency\")\n",
    "plt.ylabel(\"bkg. mistag rate\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
